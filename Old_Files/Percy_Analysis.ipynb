{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from matplotlib import rcParams\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See older versions of the file to retrieve the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV file from 'business.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading in 'extacted_restaurants_from_business.csv'\n",
    "rest_biz_csvTOpd = pd.read_csv('extracted_restaurants_from_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QXAEGFB4oINsVuTFxEYKFQ',\n",
       " 'gnKjwL_1w79qoiV3IC_xQQ',\n",
       " '1Dfx3zM-rW4n-31KeC8sJg',\n",
       " 'fweCYi8FmbJXHCqLnwuk8w',\n",
       " 'PZ-LZzSlhSe9utkQYU8pFg']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Business IDs for the restaurants\n",
    "restaurant_id_list = rest_biz_csvTOpd.business_id.tolist()\n",
    "restaurant_id_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of restaurants in the original dataset: 59371\n"
     ]
    }
   ],
   "source": [
    "print('Number of restaurants in the original dataset:',len(restaurant_id_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV file from 'review.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in 'extracted_restaurants_from_review.csv'\n",
    "rest_review_csvTOpd = pd.read_csv('extracted_restaurants_from_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index_From_review.JSON</th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>fdiNeiN_hoCxCMy2wTRW9g</td>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I'll be the first to admit that I was not exci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>G7XHMxG0bx9oBJNECG4IFg</td>\n",
       "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8e9HxxLjjqc9ez5ezzN7iQ</td>\n",
       "      <td>zvO-PJCpNk4fgAVUnExYAA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This place has gone down hill.  Clearly they h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>kbtscdyz6lvrtGjD1quQTg</td>\n",
       "      <td>8mIrX_LrOnAqWsB5JrOojQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Like walking back in time, every Saturday morn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index_From_review.JSON               review_id             business_id  \\\n",
       "0                      3  yi0R0Ugj_xUx_Nek0-_Qig  ikCg8xy5JIg_NGPx-MSIDA   \n",
       "1                      5  fdiNeiN_hoCxCMy2wTRW9g  eU_713ec6fTGNO4BegRaww   \n",
       "2                      6  G7XHMxG0bx9oBJNECG4IFg  3fw2X5bZYeW9xCz_zGhOHg   \n",
       "3                      7  8e9HxxLjjqc9ez5ezzN7iQ  zvO-PJCpNk4fgAVUnExYAA   \n",
       "4                     10  kbtscdyz6lvrtGjD1quQTg  8mIrX_LrOnAqWsB5JrOojQ   \n",
       "\n",
       "   stars                                               text  \n",
       "0    5.0  Went in for a lunch. Steak sandwich was delici...  \n",
       "1    4.0  I'll be the first to admit that I was not exci...  \n",
       "2    3.0  Tracy dessert had a big name in Hong Kong and ...  \n",
       "3    1.0  This place has gone down hill.  Clearly they h...  \n",
       "4    4.0  Like walking back in time, every Saturday morn...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column containing the old indices\n",
    "rest_review_csvTOpd.rename(columns={\"Unnamed: 0\": \"Index_From_review.JSON\"}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We wanted to look to see if potentially we would be able to figure out whether we can identify false reviews that are becoming more common on sites like Amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of reviews.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metrics(true_labels, predicted_labels):\n",
    "    print('Accuracy:', np.round(metrics.accuracy_score(true_labels, predicted_labels), 4))\n",
    "    print('Precision:', np.round(metrics.precision_score(true_labels, predicted_labels, average='weighted'), 4))\n",
    "    print('Recall:', np.round(metrics.recall_score(true_labels, predicted_labels, average='weighted'), 4))\n",
    "    print('F1-Score:', np.round(metrics.f1_score(true_labels, predicted_labels,average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4201685 restaurant reviews.\n"
     ]
    }
   ],
   "source": [
    "rest_review_length = len(rest_review_csvTOpd)\n",
    "print(\"There are {} restaurant reviews.\".format(rest_review_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_star = rest_review_csvTOpd.loc[rest_review_csvTOpd['stars'] == 1.0]\n",
    "two_star = rest_review_csvTOpd.loc[rest_review_csvTOpd['stars'] == 2.0]\n",
    "three_star = rest_review_csvTOpd.loc[rest_review_csvTOpd['stars'] == 3.0]\n",
    "four_star = rest_review_csvTOpd.loc[rest_review_csvTOpd['stars'] == 4.0]\n",
    "five_star = rest_review_csvTOpd.loc[rest_review_csvTOpd['stars'] == 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuring out what percentage of the \"rest_review_csvTOpd\" should be training data, and what percentage should be test data.\n",
    "num_train_data = int(rest_review_length * 0.8)\n",
    "print(\"For 80% of the data, there should be {} reviews.\".format(num_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with 5 Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of All Reviews in review.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.hist(rest_review_csvTOpd.stars, bins=np.arange(10)-0.5, edgecolor='black', linewidth=1.2)\n",
    "plt.xlim(0.4, 5.6)\n",
    "plt.title(\"Histogram of Ratings\")\n",
    "plt.xlabel(\"Star Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data for FIVE labels with equal amounts of each rating.\n",
    "train_data = pd.concat([one_star.text[:1600], two_star.text[:1600], three_star.text[:1600], four_star.text[:1600], five_star.text[:1600]])\n",
    "train_labels = pd.concat([one_star.stars[:1600], two_star.stars[:1600], three_star.stars[:1600], four_star.stars[:1600], five_star.stars[:1600]])\n",
    "\n",
    "# Test data for FIVE labels with equal amounts of each rating.\n",
    "test_data = pd.concat([one_star.text[1600:1700], two_star.text[1600:1700], three_star.text[1600:1700], four_star.text[1600:1700], five_star.text[1600:1700]])\n",
    "test_labels = pd.concat([one_star.stars[1600:1700], two_star.stars[1600:1700], three_star.stars[1600:1700], four_star.stars[1600:1700], five_star.stars[1600:1700]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.hist(train_labels, bins=np.arange(10)-0.5, edgecolor='black', linewidth=1.2)\n",
    "plt.xlim(0.4, 5.6)\n",
    "plt.title(\"Histogram of Train Data Ratings\")\n",
    "plt.xlabel(\"Star Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CountVectorizer with your text data\n",
    "cvector = CountVectorizer()\n",
    "# train_data = testset.text.tolist()\n",
    "vtrain = cvector.fit_transform(train_data)\n",
    "vtest = cvector.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LogisticRegression Classifier\n",
    "lr_classifier = LogisticRegression(C=0.09)\n",
    "lr_classifier.fit(vtrain, train_labels)\n",
    "train_predicted_labels = lr_classifier.predict(vtest)\n",
    "all_metrics(test_labels, train_predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_labels, train_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: Rows reflect the actual values. Columns reflect the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fairly standard confusion matrix with the majority of test_labels and predicted_labels in the same game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVctorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit TfidfVectorizer with your text data\n",
    "tvector = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "vtrain = tvector.fit_transform(train_data)\n",
    "vtest = tvector.transform(test_data)\n",
    "tvector.fit(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LogisticRegression Classifier\n",
    "lr_classifier = LogisticRegression(C=0.09)\n",
    "lr_classifier.fit(vtrain, train_labels)\n",
    "train_predicted_labels = lr_classifier.predict(vtest)\n",
    "all_metrics(test_labels, train_predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_labels, train_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What's interesting about this particular matrix is the 4th row. About 38 reviews are predicted to be 5-star reviews, but in actuality they are 4-star reviews of the restaurant. The number of predicted 5-star reviews for ones that are actually 4-star reviews shows that it is difficult to distinguish a 4-star review from a five star one. One possible reason for this is because people often reserve a 5-star style meal for truly exceptional meals. Thus even though they talk about positive aspects of the meal in their 4-star rating, they could be giving the review 4-stars just because it wasn't the \"best\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This result prompted us to think about working with less labels rather than the current schema of 5 labels, one for each star rating. Perhaps with less labels, it will be much clearer to distinguish clearer difference between labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Simplified Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data for 3 labels with equal amounts of each rating.\n",
    "train_data = pd.concat([one_star.text[:1600], two_star.text[:1600], three_star.text[:1600], four_star.text[:1600], five_star.text[:1600]])\n",
    "train_labels = pd.concat([one_star.stars[:1600], one_star.stars[:1600], three_star.stars[:1600], five_star.stars[:1600], five_star.stars[:1600]])\n",
    "\n",
    "test_data = pd.concat([one_star.text[1600:1700], two_star.text[1600:1700], three_star.text[1600:1700], four_star.text[1600:1700], five_star.text[1600:1700]])\n",
    "test_labels = pd.concat([one_star.stars[1600:1700], one_star.stars[1600:1700], three_star.stars[1600:1700], five_star.stars[1600:1700], five_star.stars[1600:1700]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The simplified data essentially simplified the 5-star rating system into three bins: bad reviews, neutral reviews, and good reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Simplified Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.hist(train_labels, bins=np.arange(10)-0.5, edgecolor='black', linewidth=1.2)\n",
    "plt.xlim(0.4, 5.6)\n",
    "plt.title(\"Histogram of Train Data Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here, the 1-star and 2-star ratings were the bad reviews, the 3-star rating consisted of the neutral reviews, and the 4-star and the 5-star ratings were the good reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CountVectorizer with your text data\n",
    "cvector = CountVectorizer()\n",
    "vtrain = cvector.fit_transform(train_data)\n",
    "vtest = cvector.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LogisticRegression Classifier\n",
    "lr_classifier = LogisticRegression(C=0.09)\n",
    "lr_classifier.fit(vtrain, train_labels)\n",
    "train_predicted_labels = lr_classifier.predict(vtest)\n",
    "all_metrics(test_labels, train_predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_labels, train_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CountVectorizer with your text data\n",
    "cvector = CountVectorizer()\n",
    "vtrain = cvector.fit_transform(train_data)\n",
    "vtest = cvector.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LogisticRegression Classifier\n",
    "lr_classifier = LogisticRegression(C=0.09)\n",
    "lr_classifier.fit(vtrain, train_labels)\n",
    "train_predicted_labels = lr_classifier.predict(vtest)\n",
    "all_metrics(test_labels, train_predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict new sentence #1.\n",
    "test_sentence = [\"I hate this place\"]\n",
    "new_test = cvector.transform(test_sentence)\n",
    "lr_classifier.predict(new_test)\n",
    "lr_classifier.predict_proba(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict new sentence #2.\n",
    "test_sentence = [\"Great place\"]\n",
    "new_test = cvector.transform(test_sentence)\n",
    "lr_classifier.predict(new_test)\n",
    "lr_classifier.predict_proba(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sentence #1, the model predicts the review to be a negative review, whereas the model predicts that sentence #2 is most likely a positive review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions Without Neutral Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redoing Analysis with Neutral Reviews\n",
    "NO3_train_data = pd.concat([one_star.text[:1600], two_star.text[:1600], four_star.text[:1600], five_star.text[:1600]])\n",
    "NO3_train_labels = pd.concat([one_star.stars[:1600], one_star.stars[:1600], five_star.stars[:1600], five_star.stars[:1600]])\n",
    "\n",
    "NO3_test_data = pd.concat([one_star.text[1600:1700], two_star.text[1600:1700], four_star.text[1600:1700], five_star.text[1600:1700]])\n",
    "NO3_test_labels = pd.concat([one_star.stars[1600:1700], one_star.stars[1600:1700], five_star.stars[1600:1700], five_star.stars[1600:1700]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CountVectorizer with your text data\n",
    "cvector = CountVectorizer()\n",
    "v_NO3_train = cvector.fit_transform(NO3_train_data)\n",
    "v_NO3_test = cvector.transform(NO3_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LogisticRegression Classifier\n",
    "lr_classifier = LogisticRegression(C=0.08)\n",
    "lr_classifier.fit(v_NO3_train, NO3_train_labels)\n",
    "train_predicted_labels = lr_classifier.predict(v_NO3_test)\n",
    "all_metrics(NO3_test_labels, train_predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(NO3_test_labels, train_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVctorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit TfidfVectorizer with your text data\n",
    "tvector = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "v_NO3_train = tvector.fit_transform(NO3_train_data)\n",
    "v_NO3_test = tvector.transform(NO3_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LogisticRegression Classifier\n",
    "lr_classifier = LogisticRegression(C=0.09)\n",
    "lr_classifier.fit(v_NO3_train, NO3_train_labels)\n",
    "train_predicted_labels = lr_classifier.predict(v_NO3_test)\n",
    "all_metrics(NO3_test_labels, train_predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(NO3_test_labels, train_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So if we throw out the moderate data (the 3-star reviews), it is clear that there is a difference between positive and negative reviews. What are some of those differences in vocabulary though?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since we're looking to compare reviews written from either end of the spectrum of restraunt ratings, the data that we're looking to train will only consist of the extremes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_train_data = pd.concat([one_star.text[:1600], five_star.text[:1600]]).tolist()\n",
    "cloud_train_labels = pd.concat([one_star.stars[:1600], five_star.stars[:1600]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords are words that are commonly used that have been purposefully programmed to be ignored.\n",
    "stopwords = STOPWORDS\n",
    "stopwords.add('food')\n",
    "stopwords.add('place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're looking to \n",
    "general = \" \".join(cloud_train_data)\n",
    "wordcloud = WordCloud(stopwords = stopwords, width=1600, height=800, max_font_size=200).generate(general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40, 40\n",
    "plt.imshow(wordcloud, interpolation= 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Word Cloud with Positive Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Reviews Dataset\n",
    "positive_reviews = five_star.text[1600:2000].tolist()\n",
    "positive = \" \".join(positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(stopwords = stopwords, width=1600, height=800, max_font_size=200).generate(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40, 40\n",
    "plt.imshow(wordcloud, interpolation= 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Word Cloud with Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Reviews Dataset\n",
    "negative_reviews = one_star.text[1600:2000].tolist()\n",
    "negative = \" \".join(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(stopwords = stopwords,width=1600, height=800, max_font_size=200).generate(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40, 40\n",
    "plt.imshow(wordcloud, interpolation= 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvector = CountVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "cvector.fit(cloud_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(cvector.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_matrix = cvector.transform(positive_reviews)\n",
    "pos_words = pos_matrix.sum(axis=0)\n",
    "pos_words_freq = [(word, pos_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "pos_tf = pd.DataFrame(list(sorted(pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "positive_unique_terms = pos_tf[~pd.DataFrame(pos_tf.Terms.tolist()).isin(stopwords).any(1)]\n",
    "positive_unique_terms[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_matrix = cvector.transform(negative_reviews)\n",
    "neg_words = neg_matrix.sum(axis=0)\n",
    "neg_words_freq = [(word, neg_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "neg_tf = pd.DataFrame(list(sorted(neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_unique_terms = neg_tf[~pd.DataFrame(neg_tf.Terms.tolist()).isin(stopwords).any(1)]\n",
    "negative_unique_terms[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvector = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "tvector.fit(cloud_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_matrix = tvector.transform(positive_reviews)\n",
    "pos_words = pos_matrix.sum(axis=0)\n",
    "pos_words_freq = [(word, pos_words[0, idx]) for word, idx in tvector.vocabulary_.items()]\n",
    "pos_tf = pd.DataFrame(list(sorted(pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_unique_terms = pos_tf[~pd.DataFrame(pos_tf.Terms.tolist()).isin(stopwords).any(1)]\n",
    "positive_unique_terms[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF-IDF analysis reveals a more words that are unique to the particular subset of positive reviews. Some words like \"great\", \"good\", and \"delicious\" are easy to understand, but then there are certain features of restaurants that get mentioned a lot too in these positive reviews, like the \"service\", \"place\", and the \"time\", presumably talking about the positive aspects of the particular restaurant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_matrix = tvector.transform(negative_reviews)\n",
    "neg_words = neg_matrix.sum(axis=0)\n",
    "neg_words_freq = [(word, neg_words[0, idx]) for word, idx in tvector.vocabulary_.items()]\n",
    "neg_tf = pd.DataFrame(list(sorted(neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "negative_unique_terms = neg_tf[~pd.DataFrame(neg_tf.Terms.tolist()).isin(stopwords).any(1)]\n",
    "negative_unique_terms[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On the other hand, the negative reviews focus on aspects of the restaurant like the \"service\", the \"order\", the \"time\", \"the food\", and the \"place\", as well as words that describe those aspects, like \"bad\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
